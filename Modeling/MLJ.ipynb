{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLJ Example\n",
    "\n",
    "The closest equivalent I've seen to `scikit-learn` for Julia is `MLJ`. `MLJ` provides a unified API wrapper around a variety of ML libraries available in Julia. \n",
    "\n",
    "Below let's take a look at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"MLJ\"); Pkg.add(\"MLJDecisionTreeInterface\")\n",
    "using MLJ, DataFramesMeta, CairoMakie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedTuple{(:sepal_length, :sepal_width, :petal_length, :petal_width, :target), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, CategoricalArrays.CategoricalVector{String, UInt32, String, CategoricalArrays.CategoricalValue{String, UInt32}, Union{}}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MLJ has some datasets builtin\n",
    "iris = load_iris();\n",
    "typeof(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────┬─────────────┬──────────────┬─────────────┬──────────────────────────────────┐\n",
      "│\u001b[1m sepal_length \u001b[0m│\u001b[1m sepal_width \u001b[0m│\u001b[1m petal_length \u001b[0m│\u001b[1m petal_width \u001b[0m│\u001b[1m target                           \u001b[0m│\n",
      "│\u001b[90m Float64      \u001b[0m│\u001b[90m Float64     \u001b[0m│\u001b[90m Float64      \u001b[0m│\u001b[90m Float64     \u001b[0m│\u001b[90m CategoricalValue{String, UInt32} \u001b[0m│\n",
      "│\u001b[90m Continuous   \u001b[0m│\u001b[90m Continuous  \u001b[0m│\u001b[90m Continuous   \u001b[0m│\u001b[90m Continuous  \u001b[0m│\u001b[90m Multiclass{3}                    \u001b[0m│\n",
      "├──────────────┼─────────────┼──────────────┼─────────────┼──────────────────────────────────┤\n",
      "│ 5.1          │ 3.5         │ 1.4          │ 0.2         │ setosa                           │\n",
      "│ 4.9          │ 3.0         │ 1.4          │ 0.2         │ setosa                           │\n",
      "│ 4.7          │ 3.2         │ 1.3          │ 0.2         │ setosa                           │\n",
      "└──────────────┴─────────────┴──────────────┴─────────────┴──────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# but it comes as a special NamedTuple with 'scitypes' inside of it, so let's make it into a dataframe\n",
    "iris = DataFrame(iris)\n",
    "# and we can `pretty` print the dataframe\n",
    "first(iris,3) |> pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a univariate time series one here too\n",
    "sunspots = MLJ.load_sunspots() |> DataFrame;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run an initial model on this DataFrame. Since `MLJ` is a wrapper on top of a bunch of other libraries, we need a way to explore the catalog of models that are available and load specific models so that we can put them to work. \n",
    "\n",
    "* See the [Model Search](https://alan-turing-institute.github.io/MLJ.jl/dev/model_search/) section in the `MLJ` docs for more details\n",
    "\n",
    "* `models(\"KMeans\")`: Lists models in the catalog that match the name \"KMeans\"\n",
    "* `info(\"KMeans\", pkg=\"Clustering\")`: Show the parameters for the \"KMeans\" model from the \"Clustering\" package\n",
    "* `doc(\"KMeans\", pkg=\"Clustering\")`: Show the docs for the \"KMeans\" model from the \"Clustering\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬──────────────┬───────────────────┬──────────────────────────────────┬───────────────┐\n",
      "│\u001b[1m name    \u001b[0m│\u001b[1m package_name \u001b[0m│\u001b[1m human_name        \u001b[0m│\u001b[1m hyperparameters                  \u001b[0m│\u001b[1m is_pure_julia \u001b[0m│\n",
      "│\u001b[90m String  \u001b[0m│\u001b[90m String       \u001b[0m│\u001b[90m String            \u001b[0m│\u001b[90m Tuple{Symbol, Symbol, Symbol}    \u001b[0m│\u001b[90m Bool          \u001b[0m│\n",
      "│\u001b[90m Textual \u001b[0m│\u001b[90m Textual      \u001b[0m│\u001b[90m Textual           \u001b[0m│\u001b[90m Tuple{Unknown, Unknown, Unknown} \u001b[0m│\u001b[90m Count         \u001b[0m│\n",
      "├─────────┼──────────────┼───────────────────┼──────────────────────────────────┼───────────────┤\n",
      "│ KMeans  │ Clustering   │ K-means clusterer │ (:k, :metric, :init)             │ true          │\n",
      "└─────────┴──────────────┴───────────────────┴──────────────────────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Show an example as a dataframe\n",
    "example = info(\"KMeans\", pkg=\"Clustering\") |> pairs |> collect |> DataFrame\n",
    "example[1,[\"name\", \"package_name\", \"human_name\", \"hyperparameters\", \"is_pure_julia\"]] |> DataFrame |> pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's an example of running the KMeans model with $k=3$ to split the `iris` data into 3 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Tuple{CategoricalArrays.CategoricalValue{Int64, UInt32}, CategoricalArrays.CategoricalValue{String, UInt32}}}:\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")\n",
       " (1, \"setosa\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KMeans = @load KMeans pkg=Clustering verbosity=0\n",
    "# Split the dataframe into y and X, where y is the column `target`  and X is everything else\n",
    "y, X = unpack(iris, ==(:target))\n",
    "model = KMeans(k=3)\n",
    "mach = machine(model, X) |> fit!\n",
    "\n",
    "yhat = predict(mach, X)\n",
    "\n",
    "# Check cluster assignments\n",
    "compare = zip(yhat, y) |> collect\n",
    "compare[1:8] # clusters align with classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review what happened in the cell above:\n",
    "\n",
    "* `@load`: loads the specified model from the catalog and brings it in to the environment\n",
    "* `unpack(iris, ==(:target))`: horizontally split the `iris` data into X and y, where y are all columns called \"target\" (here we use the symbol `:target`)\n",
    "* `KMeans(k=3)`: Instantiate the KMeans model (from the `@load` on line 1) and set $k=3$\n",
    "*  `machine(model, X) |> fit!`: We create a 'machine' that combines a model with training data and then `fit!` trains the model on the data\n",
    "   *  The pipe operator `|>` is similar to method chaining in python or `dplyr`'s pipe in R\n",
    "*  `predict(mach, X)`: Provides the predicted cluster assignments for each row of $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also created a fitted machine that we can call things like `fitted_params`, which in the case of `KMeans` just has a single parameter `centers` and each row corresponds to a column from the `iris` training data (sepal length, sepal width, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×3 Matrix{Float64}:\n",
       " 5.006  5.88361  6.85385\n",
       " 3.418  2.74098  3.07692\n",
       " 1.464  4.38852  5.71538\n",
       " 0.244  1.43443  2.05385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitted_params(mach).centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can generate a report on the fitted machine with `report` to get some of the key outputs. This includes:\n",
    "\n",
    "* `assignments`: cluster assignments\n",
    "* `cluster_labels`: cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(assignments = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  3, 3, 2, 3, 3, 3, 2, 3, 3, 2],\n",
       " cluster_labels = CategoricalArrays.CategoricalValue{Int64, UInt32}[1, 2, 3],)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Let's build on the clustering example with an example from supervised learning. Below we'll take the popular boston housing dataset so we can show how to use `MLJ` to do things like a train/test split and evaluating against accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>3×14 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Crim</th><th style = \"text-align: left;\">Zn</th><th style = \"text-align: left;\">Indus</th><th style = \"text-align: left;\">Chas</th><th style = \"text-align: left;\">NOx</th><th style = \"text-align: left;\">Rm</th><th style = \"text-align: left;\">Age</th><th style = \"text-align: left;\">Dis</th><th style = \"text-align: left;\">Rad</th><th style = \"text-align: left;\">Tax</th><th style = \"text-align: left;\">PTRatio</th><th style = \"text-align: left;\">Black</th><th style = \"text-align: left;\">LStat</th><th style = \"text-align: left;\">MedV</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0.00632</td><td style = \"text-align: right;\">18.0</td><td style = \"text-align: right;\">2.31</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.538</td><td style = \"text-align: right;\">6.575</td><td style = \"text-align: right;\">65.2</td><td style = \"text-align: right;\">4.09</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">296.0</td><td style = \"text-align: right;\">15.3</td><td style = \"text-align: right;\">396.9</td><td style = \"text-align: right;\">4.98</td><td style = \"text-align: right;\">24.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.02731</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">7.07</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.469</td><td style = \"text-align: right;\">6.421</td><td style = \"text-align: right;\">78.9</td><td style = \"text-align: right;\">4.9671</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">242.0</td><td style = \"text-align: right;\">17.8</td><td style = \"text-align: right;\">396.9</td><td style = \"text-align: right;\">9.14</td><td style = \"text-align: right;\">21.6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.02729</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">7.07</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.469</td><td style = \"text-align: right;\">7.185</td><td style = \"text-align: right;\">61.1</td><td style = \"text-align: right;\">4.9671</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">242.0</td><td style = \"text-align: right;\">17.8</td><td style = \"text-align: right;\">392.83</td><td style = \"text-align: right;\">4.03</td><td style = \"text-align: right;\">34.7</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& Crim & Zn & Indus & Chas & NOx & Rm & Age & Dis & Rad & Tax & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Int64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.00632 & 18.0 & 2.31 & 0 & 0.538 & 6.575 & 65.2 & 4.09 & 1.0 & 296.0 & $\\dots$ \\\\\n",
       "\t2 & 0.02731 & 0.0 & 7.07 & 0 & 0.469 & 6.421 & 78.9 & 4.9671 & 2.0 & 242.0 & $\\dots$ \\\\\n",
       "\t3 & 0.02729 & 0.0 & 7.07 & 0 & 0.469 & 7.185 & 61.1 & 4.9671 & 2.0 & 242.0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×14 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Crim    \u001b[0m\u001b[1m Zn      \u001b[0m\u001b[1m Indus   \u001b[0m\u001b[1m Chas  \u001b[0m\u001b[1m NOx     \u001b[0m\u001b[1m Rm      \u001b[0m\u001b[1m Age     \u001b[0m\u001b[1m Dis     \u001b[0m\u001b[1m R\u001b[0m ⋯\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 0.00632     18.0     2.31      0    0.538    6.575     65.2   4.09      ⋯\n",
       "   2 │ 0.02731      0.0     7.07      0    0.469    6.421     78.9   4.9671\n",
       "   3 │ 0.02729      0.0     7.07      0    0.469    7.185     61.1   4.9671\n",
       "\u001b[36m                                                               6 columns omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in boston housing market data\n",
    "boston = load_boston() |> DataFrame\n",
    "first(boston,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(\n",
       "  max_depth = -1, \n",
       "  min_samples_leaf = 1, \n",
       "  min_samples_split = 2, \n",
       "  min_purity_increase = 0.0, \n",
       "  n_subfeatures = -1, \n",
       "  n_trees = 10, \n",
       "  sampling_fraction = 0.7, \n",
       "  feature_importance = :impurity, \n",
       "  rng = Random._GLOBAL_RNG())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Test Split with `partition`\n",
    "train, test = partition(boston, 0.8, rng=42);\n",
    "\n",
    "# As before, unpack to horizontally split into y and X\n",
    "y_train, X_train = unpack(train, ==(:MedV))\n",
    "y_test, X_test = unpack(test, ==(:MedV));\n",
    "\n",
    "# Load in our model and instantiate it\n",
    "Tree = @load RandomForestRegressor pkg=DecisionTree verbosity=0;\n",
    "tree = Tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build our machine with the training data, and fit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: RandomForestRegressor(max_depth = -1, …)\n",
       "  args: \n",
       "    1:\tSource @537 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Count}}}\n",
       "    2:\tSource @931 ⏎ AbstractVector{Continuous}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mach = machine(tree, X_train, y_train) |> fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Now we want to check our accuracy in terms of RMSE - instead of doing the old `predict` one time, let's use `evaluate` to see how this model performs with 5-fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  measure, operation, measurement, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_rows\n",
       "Extract:\n",
       "┌────────────────────────┬───────────┬─────────────┬─────────┬──────────────────\n",
       "│\u001b[22m measure                \u001b[0m│\u001b[22m operation \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\u001b[22m per_fold       \u001b[0m ⋯\n",
       "├────────────────────────┼───────────┼─────────────┼─────────┼──────────────────\n",
       "│ RootMeanSquaredError() │ predict   │ 3.85        │ 0.613   │ [4.83, 3.62, 3. ⋯\n",
       "└────────────────────────┴───────────┴─────────────┴─────────┴──────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = evaluate!(mach, resampling=CV(nfolds=5, rng=42), measure=rms, operation=predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really cool - it lets you specify the evaluation strategy quite nicely. \n",
    "\n",
    "* See [measure list](https://alan-turing-institute.github.io/MLJ.jl/stable/performance_measures/#List-of-measures) for a list of possible performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
